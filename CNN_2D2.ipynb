{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import correlate2d\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "\n",
    "class Convolution:\n",
    "    \n",
    "    def __init__(self, input_shape, filter_size, num_filters):\n",
    "        input_height, input_width = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Size of outputs and filters\n",
    "        \n",
    "        self.filter_shape = (num_filters, filter_size, filter_size) # (3,3)\n",
    "        self.output_shape = (num_filters, input_height - filter_size + 1, input_width - filter_size + 1)\n",
    "        \n",
    "        self.filters = np.random.randn(*self.filter_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        # Initialized the input value\n",
    "        output = np.zeros(self.output_shape)\n",
    "        for i in range(self.num_filters):\n",
    "            output[i] = correlate2d(self.input_data, self.filters[i], mode=\"valid\")\n",
    "        #Applying Relu Activtion function\n",
    "        output = np.maximum(output, 0)\n",
    "        return output \n",
    "    def backward(self, dL_dout, lr):\n",
    "        # Create a random dL_dout array to accommodate output gradients\n",
    "        h = int(self.input_data.shape[0])\n",
    "        w = int(self.input_data.shape[1])   \n",
    "        dL_dinput = np.zeros((h, w, self.num_filters), dtype=np.float64)\n",
    "        dL_dfilters = np.zeros_like(self.filters)\n",
    "\n",
    "        for i in range(self.num_filters):\n",
    "                # Calculating the gradient of loss with respect to kernels\n",
    "                dL_dfilters[i] = correlate2d(self.input_data, dL_dout[i],mode=\"valid\")\n",
    "                dL_dinput = dL_dinput.astype(np.float64)\n",
    "                dL_dout[i] = dL_dout[i].astype(np.float64)\n",
    "                self.filters[i] = self.filters[i]\n",
    "                # Calculating the gradient of loss with respect to inputs\n",
    "                dL_dinput[:,:,i] += fftconvolve(dL_dout[i].astype(np.float64), self.filters[i].astype(np.float64))\n",
    "\n",
    "        # Updating the parameters with learning rate\n",
    "        self.filters -= lr * dL_dfilters\n",
    "        self.biases -= lr * dL_dout\n",
    "\n",
    "        # returning the gradient of inputs\n",
    "        return dL_dinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def forward(self, input_data):\n",
    "\n",
    "            self.input_data = input_data\n",
    "            self.num_channels, self.input_height, self.input_width = input_data.shape\n",
    "            self.output_height = self.input_height // self.pool_size\n",
    "            self.output_width = self.input_width // self.pool_size\n",
    "\n",
    "            # Determining the output shape\n",
    "            self.output = np.zeros((self.num_channels, self.output_height, self.output_width))\n",
    "\n",
    "            # Iterating over different channels\n",
    "            for c in range(self.num_channels):\n",
    "                # Looping through the height\n",
    "                for i in range(self.output_height):\n",
    "                    # looping through the width\n",
    "                    for j in range(self.output_width):\n",
    "\n",
    "                        # Starting postition\n",
    "                        start_i = i * self.pool_size\n",
    "                        start_j = j * self.pool_size\n",
    "\n",
    "                        # Ending Position\n",
    "                        end_i = start_i + self.pool_size\n",
    "                        end_j = start_j + self.pool_size\n",
    "\n",
    "                        # Creating a patch from the input data\n",
    "                        patch = input_data[c, start_i:end_i, start_j:end_j]\n",
    "\n",
    "                        #Finding the maximum value from each patch/window\n",
    "                        self.output[c, i, j] = np.max(patch)\n",
    "\n",
    "            return self.output\n",
    "    \n",
    "    def backward(self, dL_dout):\n",
    "        dL_dinput = np.zeros_like(self.input_data)\n",
    "\n",
    "        for c in range(self.num_channels):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    start_i = i * self.pool_size\n",
    "                    start_j = j * self.pool_size\n",
    "\n",
    "                    end_i = start_i + self.pool_size\n",
    "                    end_j = start_j + self.pool_size\n",
    "                    patch = self.input_data[c, start_i:end_i, start_j:end_j]\n",
    "\n",
    "                    mask = patch == np.max(patch)\n",
    "\n",
    "                    dL_dinput[c,start_i:end_i, start_j:end_j] = dL_dout[c, i, j] * mask\n",
    "\n",
    "        return dL_dinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fully_Connected:\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size # Size of the inputs coming\n",
    "        self.output_size = output_size # Size of the output producing\n",
    "        self.weights = np.random.randn(output_size, self.input_size)\n",
    "        self.biases = np.random.rand(output_size, 1)\n",
    "    def softmax(self, z):\n",
    "        # Shift the input values to avoid numerical instability\n",
    "        shifted_z = z - np.max(z)\n",
    "        exp_values = np.exp(shifted_z)\n",
    "        sum_exp_values = np.sum(exp_values, axis=0)\n",
    "        log_sum_exp = np.log(sum_exp_values)\n",
    "\n",
    "        # Compute the softmax probabilities\n",
    "        probabilities = exp_values / sum_exp_values\n",
    "\n",
    "        return probabilities\n",
    "    def softmax_derivative(self, s):\n",
    "        return np.diagflat(s) - np.dot(s, s.T)\n",
    "    def forward(self, input_data):\n",
    "            self.input_data = input_data\n",
    "            # Flattening the inputs from the previous layer into a vector\n",
    "            flattened_input = input_data.flatten().reshape(1, -1)\n",
    "            self.z = np.dot(self.weights, flattened_input.T) + self.biases\n",
    "\n",
    "            # Applying Softmax\n",
    "            self.output = self.softmax(self.z)\n",
    "            return self.output\n",
    "    def backward(self, dL_dout, lr):\n",
    "            # Calculate the gradient of the loss with respect to the pre-activation (z)\n",
    "            dL_dy = np.dot(self.softmax_derivative(self.output), dL_dout)\n",
    "            # Calculate the gradient of the loss with respect to the weights (dw)\n",
    "            dL_dw = np.dot(dL_dy, self.input_data.flatten().reshape(1, -1))\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the biases (db)\n",
    "            dL_db = dL_dy\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the input data (dL_dinput)\n",
    "            dL_dinput = np.dot(self.weights.T, dL_dy)\n",
    "            dL_dinput = dL_dinput.reshape(self.input_data.shape)\n",
    "\n",
    "            # Update the weights and biases based on the learning rate and gradients\n",
    "            self.weights -= lr * dL_dw\n",
    "            self.biases -= lr * dL_db\n",
    "\n",
    "            # Return the gradient of the loss with respect to the input data\n",
    "            return dL_dinput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predictions, targets):\n",
    "\n",
    "    num_samples = 10\n",
    "\n",
    "    # Avoid numerical instability by adding a small epsilon value\n",
    "    epsilon = 1e-7\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -np.sum(targets * np.log(predictions)) / num_samples\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_loss_gradient(actual_labels, predicted_probs):\n",
    "    num_samples = actual_labels.shape[0]\n",
    "    gradient = -actual_labels / (predicted_probs + 1e-7) / num_samples\n",
    "\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:\\MachineLearning\\CNN\\Data_skincancer\\hmnist_28_28_L.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:-1].values\n",
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(-1,28,28)\n",
    "X_test=X_test.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e080208410>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=X_train/255-0.5\n",
    "X_test_scaled=X_test/255-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Convolution(X_train_scaled[0].shape, 6, 1)\n",
    "pool = MaxPool(2)\n",
    "full = Fully_Connected(121, 7)\n",
    "\n",
    "def train_network(X, y, conv, pool, full, lr=0.01, epochs=200):\n",
    "    for epoch in range(10):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            # Forward pass\n",
    "            conv_out = conv.forward(X[i])\n",
    "            pool_out = pool.forward(conv_out)\n",
    "            full_out = full.forward(pool_out)\n",
    "            loss = cross_entropy_loss(full_out.flatten(), y[i])\n",
    "            total_loss += loss\n",
    "\n",
    "            # Converting to One-Hot encoding\n",
    "            one_hot_pred = np.zeros_like(full_out)\n",
    "            one_hot_pred[np.argmax(full_out)] = 1\n",
    "            one_hot_pred = one_hot_pred.flatten()\n",
    "\n",
    "            num_pred = np.argmax(one_hot_pred)\n",
    "            num_y = np.argmax(y[i])\n",
    "\n",
    "            if num_pred == num_y:\n",
    "                correct_predictions += 1\n",
    "            # Backward pass\n",
    "            gradient = cross_entropy_loss_gradient(y[i], full_out.flatten()).reshape((-1, 1))\n",
    "            full_back = full.backward(gradient, lr)\n",
    "            pool_back = pool.backward(full_back,)\n",
    "            conv_back = conv.backward(pool_back, lr)\n",
    "\n",
    "        # Print epoch statistics\n",
    "        average_loss = total_loss / len(X)\n",
    "        accuracy = correct_predictions / len(X_train) * 100.0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_sample, conv, pool, full):\n",
    "    # Forward pass through Convolution and pooling\n",
    "    conv_out = conv.forward(input_sample)\n",
    "    pool_out = pool.forward(conv_out)\n",
    "    # Flattening\n",
    "    flattened_output = pool_out.flatten()\n",
    "    # Forward pass through fully connected layer\n",
    "    predictions = full.forward(flattened_output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Loss: 0.1547 - Accuracy: 60.31%\n",
      "Epoch 2/200 - Loss: 0.1273 - Accuracy: 65.64%\n",
      "Epoch 3/200 - Loss: 0.1197 - Accuracy: 66.79%\n",
      "Epoch 4/200 - Loss: 0.1165 - Accuracy: 66.74%\n",
      "Epoch 5/200 - Loss: 0.1149 - Accuracy: 66.45%\n",
      "Epoch 6/200 - Loss: 0.1140 - Accuracy: 66.54%\n",
      "Epoch 7/200 - Loss: 0.1135 - Accuracy: 66.59%\n",
      "Epoch 8/200 - Loss: 0.1130 - Accuracy: 66.53%\n",
      "Epoch 9/200 - Loss: 0.1127 - Accuracy: 66.49%\n",
      "Epoch 10/200 - Loss: 0.1125 - Accuracy: 66.33%\n"
     ]
    }
   ],
   "source": [
    "train_network(X_train_scaled, y_train, conv, pool, full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
